{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "linear-mount",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "laden-opera",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_four_corner = tf.keras.models.load_model('D:/Github/Spliddit/models/four_corner_model/full_model')\n",
    "model_corner_refiner = tf.keras.models.load_model('D:/Github/Spliddit/models/corner_refiner_model/full_model')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "complete-pacific",
   "metadata": {},
   "source": [
    "# Preparing the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "ranging-student",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_path = 'D:/Github/Spliddit/testset/'\n",
    "files = os.listdir(test_path)\n",
    "index = 6\n",
    "test_img = cv2.imread(test_path + files[index], 1)\n",
    "original_img = test_img.copy()\n",
    "test_img = cv2.resize(test_img, (100, 100))\n",
    "test_img = test_img.astype('float32') / 255\n",
    "test_img = test_img.reshape((-1, 100, 100, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "noted-appreciation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 100, 100, 3)"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_img.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "little-replica",
   "metadata": {},
   "source": [
    "# Four Corner Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "possible-thesaurus",
   "metadata": {},
   "outputs": [],
   "source": [
    "four_corners = model_four_corner.predict(test_img).reshape((8))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "macro-brook",
   "metadata": {},
   "source": [
    "1.) Upscaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "daily-privilege",
   "metadata": {},
   "outputs": [],
   "source": [
    "def upscale_result(four_corners, img):\n",
    "    height, width = img.shape[:2]\n",
    "    pairs = get_coord_pairs(four_corners)\n",
    "    scaled = []\n",
    "    for pair in pairs:\n",
    "        scaled.append((int(pair[0] * width), int(pair[1] * height)))\n",
    "    return scaled\n",
    "    \n",
    "def get_coord_pairs(coords):\n",
    "    return [(coords[0], coords[1]), (coords[2], coords[3]), (coords[4], coords[5]), (coords[6], coords[7])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "opening-object",
   "metadata": {},
   "outputs": [],
   "source": [
    "four_corners = upscale_result(four_corners, original_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "durable-cotton",
   "metadata": {},
   "source": [
    "2.) Extract corners"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "protective-compiler",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_corners(img, coords):\n",
    "    height, width = img.shape[:2]\n",
    "    tl, tr, br, bl = four_corners\n",
    "    tl_tr_x_diff = abs(tl[0] - tr[0])\n",
    "    tl_bl_y_diff = abs(tl[1] - bl[1])\n",
    "    tr_br_y_diff = abs(tr[1] - br[1])\n",
    "    br_bl_x_diff = abs(br[0] - bl[0])\n",
    "    \n",
    "    tl_x = int(tl[0] + 0.5*tl_tr_x_diff)\n",
    "    tl_y = int(tl[1] + 0.5*tl_bl_y_diff)\n",
    "    tr_y = int(tr[1] + 0.5*tr_br_y_diff)\n",
    "    br_x = int(bl[0] + 0.5*br_bl_x_diff)\n",
    "    \n",
    "    crop_tl = img[0:tl_y, 0:tl_x]\n",
    "    crop_tr = img[0:tr_y, tl_x:width]\n",
    "    crop_br = img[tr_y:height, br_x:width]\n",
    "    crop_bl = img[tl_y:height, 0:br_x]\n",
    "    \n",
    "    return crop_tl, crop_tr, crop_br, crop_bl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "processed-literacy",
   "metadata": {},
   "outputs": [],
   "source": [
    "crop_tl, crop_tr, crop_br, crop_bl = extract_corners(original_img, four_corners)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "every-astronomy",
   "metadata": {},
   "outputs": [],
   "source": [
    "tl_height, tl_width = crop_tl.shape[:2]\n",
    "tr_height, tr_width = crop_tr.shape[:2]\n",
    "br_height, br_width = crop_br.shape[:2]\n",
    "bl_height, bl_width = crop_bl.shape[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "confirmed-crossing",
   "metadata": {},
   "source": [
    "# Refine Corners"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "animated-router",
   "metadata": {},
   "outputs": [],
   "source": [
    "def upscale_result(corner, img):\n",
    "    height, width = img.shape[:2]\n",
    "    x_scaled = int(corner[0] * width)\n",
    "    y_scaled = int(corner[1] * height)\n",
    "    return (x_scaled, y_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "private-cycling",
   "metadata": {},
   "outputs": [],
   "source": [
    "tl = cv2.resize(crop_tl, (100,100)).reshape((-1, 100, 100, 3))\n",
    "tr = cv2.resize(crop_tr, (100,100)).reshape((-1, 100, 100, 3))\n",
    "br = cv2.resize(crop_br, (100,100)).reshape((-1, 100, 100, 3))\n",
    "bl = cv2.resize(crop_bl, (100,100)).reshape((-1, 100, 100, 3))\n",
    "\n",
    "tl = tl.astype('float32') / 255\n",
    "tr = tr.astype('float32') / 255\n",
    "br = br.astype('float32') / 255\n",
    "bl = bl.astype('float32') / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "corrected-jimmy",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tl_pred = model_corner_refiner.predict(tl)[0]\n",
    "tr_pred = model_corner_refiner.predict(tr)[0]\n",
    "br_pred = model_corner_refiner.predict(br)[0]\n",
    "bl_pred = model_corner_refiner.predict(bl)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "square-albuquerque",
   "metadata": {},
   "outputs": [],
   "source": [
    "tl_scaled = upscale_result(tl_pred, crop_tl)\n",
    "tr_scaled = upscale_result(tr_pred, crop_tr)\n",
    "br_scaled = upscale_result(br_pred, crop_br)\n",
    "bl_scaled = upscale_result(bl_pred, crop_bl)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "opposite-louisville",
   "metadata": {},
   "source": [
    "# Recursive Refinement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "surprised-being",
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_image(img, coords, retain_factor):\n",
    "    \n",
    "    left_diff = abs(0 - coords[0])\n",
    "    right_diff = abs(img.shape[1] - coords[0])\n",
    "    top_diff = abs(0 - coords[1])\n",
    "    bottom_diff = abs(img.shape[0] - coords[1])\n",
    "    \n",
    "    left_crop = int(left_diff * (1-retain_factor))\n",
    "    right_crop = int(right_diff * (1-retain_factor))\n",
    "    top_crop = int(top_diff * (1-retain_factor))\n",
    "    bottom_crop = int(bottom_diff * (1-retain_factor))\n",
    "    \n",
    "    cropped =  img[0 + top_crop : img.shape[0] - bottom_crop, 0 + left_crop : img.shape[1] - right_crop]\n",
    "    return cropped, [top_crop, bottom_crop, left_crop, right_crop]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "narrow-bunch",
   "metadata": {},
   "outputs": [],
   "source": [
    "tl_diffs, tr_diffs, br_diffs, bl_diffs = [], [], [], []\n",
    "tl_original, tr_original, br_original, bl_original = crop_tl.copy(), crop_tr.copy(), crop_br.copy(), crop_bl.copy()\n",
    "\n",
    "debug_coord = []\n",
    "debug_img = []\n",
    "\n",
    "while True:\n",
    "    if ((tl_original.shape[0] * 0.75 < 100) or (tl_original.shape[1] * 0.75 < 100) or\n",
    "        (tr_original.shape[0] * 0.75 < 100) or (tr_original.shape[0] * 0.75 < 100) or\n",
    "        (br_original.shape[0] * 0.75 < 100) or (br_original.shape[0] * 0.75 < 100) or\n",
    "        (bl_original.shape[0] * 0.75 < 100) or (bl_original.shape[0] * 0.75 < 100)):\n",
    "        break\n",
    "    \n",
    "    crop_tl, tl_diff = crop_image(tl_original, tl_scaled, 0.75)\n",
    "    crop_tr, tr_diff = crop_image(tr_original, tr_scaled, 0.75)\n",
    "    crop_br, br_diff = crop_image(br_original, br_scaled, 0.75)\n",
    "    crop_bl, bl_diff = crop_image(bl_original, bl_scaled, 0.75)\n",
    "    \n",
    "    tl_original, tr_original, br_original, bl_original = crop_tl.copy(), crop_tr.copy(), crop_br.copy(), crop_bl.copy()\n",
    "    \n",
    "    tl_diffs.append(tl_diff)\n",
    "    tr_diffs.append(tr_diff)\n",
    "    br_diffs.append(br_diff)\n",
    "    bl_diffs.append(bl_diff)\n",
    "    \n",
    "    crop_tl = cv2.resize(crop_tl, (100, 100)).reshape((-1, 100, 100, 3)).astype('float32') / 255\n",
    "    crop_tr = cv2.resize(crop_tr, (100, 100)).reshape((-1, 100, 100, 3)).astype('float32') / 255\n",
    "    crop_br = cv2.resize(crop_br, (100, 100)).reshape((-1, 100, 100, 3)).astype('float32') / 255\n",
    "    crop_bl = cv2.resize(crop_bl, (100, 100)).reshape((-1, 100, 100, 3)).astype('float32') / 255\n",
    "    \n",
    "    tl_pred =  model_corner_refiner.predict(crop_tl)[0]\n",
    "    tr_pred =  model_corner_refiner.predict(crop_tr)[0]\n",
    "    br_pred =  model_corner_refiner.predict(crop_br)[0]\n",
    "    bl_pred =  model_corner_refiner.predict(crop_bl)[0]\n",
    "    \n",
    "    tl_scaled = upscale_result(tl_pred, tl_original)\n",
    "    tr_scaled = upscale_result(tr_pred, tr_original)\n",
    "    br_scaled = upscale_result(br_pred, br_original)\n",
    "    bl_scaled = upscale_result(bl_pred, bl_original)\n",
    "    \n",
    "    debug_coord.append(br_scaled)\n",
    "    debug_img.append(br_original)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "registered-credit",
   "metadata": {},
   "outputs": [],
   "source": [
    "#i = 3\n",
    "\n",
    "#temp = debug_img[i].copy()\n",
    "#cv2.circle(temp, debug_coord[i], 5,(255,0,0), thickness=-1)\n",
    "#temp = cv2.resize(temp, (600, 800))\n",
    "#cv2.imshow(\"Outline\", temp)\n",
    "#cv2.waitKey(0)\n",
    "#cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "thermal-copper",
   "metadata": {},
   "source": [
    "# Leading the refined prediction back to the original image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "strange-browser",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_add_tl = [x[0] for x in tl_diffs]\n",
    "left_add_tl = [x[2] for x in tl_diffs]\n",
    "\n",
    "tl_coord_final = (tl_scaled[0] + sum(left_add_tl), tl_scaled[1] + sum(top_add_tl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "attempted-emerald",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_add_tr = [x[0] for x in tr_diffs]\n",
    "left_add_tr = [x[2] for x in tr_diffs]\n",
    "\n",
    "tr_coord_final = (tr_scaled[0] + sum(left_add_tr) + tl_width, tr_scaled[1] + sum(top_add_tr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "dramatic-shanghai",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_add_br = [x[0] for x in br_diffs]\n",
    "left_add_br = [x[2] for x in br_diffs]\n",
    "\n",
    "br_coord_final = (br_scaled[0] + sum(left_add_br) + bl_width, br_scaled[1] + sum(top_add_br) + tr_height)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "consecutive-classic",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_add_bl = [x[0] for x in bl_diffs]\n",
    "left_add_bl = [x[2] for x in bl_diffs]\n",
    "\n",
    "bl_coord_final = (bl_scaled[0] + sum(left_add_bl), bl_scaled[1] + sum(top_add_bl) + tl_height)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "exceptional-worse",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = original_img.copy()\n",
    "cv2.circle(temp, tl_coord_final, 5,(255,0,0), thickness=-1)\n",
    "cv2.circle(temp, tr_coord_final, 5,(255,0,0), thickness=-1)\n",
    "cv2.circle(temp, br_coord_final, 5,(255,0,0), thickness=-1)\n",
    "cv2.circle(temp, bl_coord_final, 5,(255,0,0), thickness=-1)\n",
    "temp = cv2.resize(temp, (600, 800))\n",
    "cv2.imshow(\"Outline\", temp)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "disabled-gilbert",
   "metadata": {},
   "source": [
    "# Bild ausschneiden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "mathematical-straight",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_left_x = min([tl_coord_final[0],tr_coord_final[0],br_coord_final[0],bl_coord_final[0]])\n",
    "top_left_y = min([tl_coord_final[1],tr_coord_final[1],br_coord_final[1],bl_coord_final[1]])\n",
    "bot_right_x = max([tl_coord_final[0],tr_coord_final[0],br_coord_final[0],bl_coord_final[0]])\n",
    "bot_right_y = max([tl_coord_final[1],tr_coord_final[1],br_coord_final[1],bl_coord_final[1]])\n",
    "\n",
    "img_cropped = original_img[top_left_y:bot_right_y+1, top_left_x:bot_right_x+1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "differential-retail",
   "metadata": {},
   "source": [
    "# Ergebnis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "textile-tiffany",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_size(x, y, max_x, max_y):\n",
    "    \"\"\"Scales two coordinates x and y so that\n",
    "    they keep their ratio until either max_x or\n",
    "    max_y is reached.\"\"\"\n",
    "    if (x > y):\n",
    "        x_increment = 1\n",
    "        y_increment = y/x\n",
    "    elif (x < y):\n",
    "        x_increment = x/y\n",
    "        y_increment = 1\n",
    "    else:\n",
    "        x_increment = 1\n",
    "        y_increment = 1\n",
    "    if((x <= max_x) and (y <= max_y)):\n",
    "        while(True):\n",
    "            if((x + x_increment >= max_x) or (y + y_increment >= max_x)):\n",
    "                return x, y\n",
    "            else:\n",
    "                x = x + x_increment\n",
    "                y = y + y_increment\n",
    "    else:\n",
    "        while(True):\n",
    "            if((x <= max_x) and (y  <= max_y)):\n",
    "                return x, y\n",
    "            else:\n",
    "                x = x - x_increment\n",
    "                y = y - y_increment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "documentary-speed",
   "metadata": {},
   "outputs": [],
   "source": [
    "y, x, z = original_img.shape\n",
    "x_scaled, y_scaled = scale_size(x, y, 1500, 800)\n",
    "cv2.namedWindow('image',cv2.WINDOW_NORMAL)\n",
    "cv2.resizeWindow('image', (int(x_scaled), int(y_scaled)))\n",
    "cv2.imshow('image', original_img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "graphic-attack",
   "metadata": {},
   "outputs": [],
   "source": [
    "y, x, z = img_cropped.shape\n",
    "x_scaled, y_scaled = scale_size(x, y, 1500, 800)\n",
    "cv2.namedWindow('image',cv2.WINDOW_NORMAL)\n",
    "cv2.resizeWindow('image', (int(x_scaled), int(y_scaled)))\n",
    "cv2.imshow('image', img_cropped)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "angry-bulgaria",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
